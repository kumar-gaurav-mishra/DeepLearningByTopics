{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d23e8814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib_inline.backend_inline as backend_inline\n",
    "\n",
    "backend_inline.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "\n",
    "#### Pytorch device specific configuration ###\n",
    "# # Pytorch Gpu Configuration for Cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Pytorch Gpu Configuration for directml(AMD GPU)\n",
    "# import torch_directml\n",
    "\n",
    "# device = torch_directml.device()\n",
    "\n",
    "# Set default device\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9587c005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1:  Parameter containing:\n",
      "tensor([[0.0161, 0.7096, 0.0433,  ..., 0.9262, 0.5855, 0.0548],\n",
      "        [0.6331, 0.1260, 0.6183,  ..., 0.3255, 0.8295, 0.3883],\n",
      "        [0.1915, 0.7793, 0.2995,  ..., 0.1512, 0.1433, 0.7554],\n",
      "        ...,\n",
      "        [0.7483, 0.4784, 0.7876,  ..., 0.8694, 0.9239, 0.4321],\n",
      "        [0.8037, 0.6995, 0.0942,  ..., 0.0656, 0.0370, 0.1956],\n",
      "        [0.2197, 0.0178, 0.6179,  ..., 0.0504, 0.7625, 0.0594]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "\n",
      "\n",
      "\n",
      "torch.Size([128, 50])\n",
      "torch.Size([50, 128])\n",
      "\n",
      "\n",
      "\n",
      "torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "# Create input matrix\n",
    "x = torch.rand(10, 50)\n",
    "W1 = nn.Parameter(torch.rand(128, 50))\n",
    "\n",
    "# Let's see what W1 is\n",
    "print(\"W1: \", W1)\n",
    "print('\\n\\n')\n",
    "\n",
    "# Its size and the size of its transpose\n",
    "print(W1.shape)\n",
    "print(W1.t().shape)\n",
    "print('\\n\\n')\n",
    "\n",
    "# compute an output\n",
    "y = x@W1.t()\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "382c717a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=128, out_features=50, bias=True)\n",
      "\n",
      "\n",
      "\n",
      "torch.Size([50, 128])\n",
      "torch.Size([128, 50])\n",
      "\n",
      "\n",
      "\n",
      "torch.Size([10, 50]) torch.Size([50, 128])\n",
      "torch.Size([10, 128])\n"
     ]
    }
   ],
   "source": [
    "# Now try again with the Linear method\n",
    "W2 = nn.Linear(128, 50)\n",
    "\n",
    "# Let's see what W2 is\n",
    "print(W2)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Its size and the size of its transpose\n",
    "print(W2.weight.shape)\n",
    "print(W2.weight.t().shape)\n",
    "print('\\n\\n')\n",
    "\n",
    "# compute an output\n",
    "print(x.shape, W2.weight.shape)\n",
    "y = x @ (W2.weight)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77a49aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 50])\n",
      "torch.Size([50, 128])\n"
     ]
    }
   ],
   "source": [
    "# confusion from the previous cells\n",
    "print(W1.shape)\n",
    "print(W2.weight.shape)\n",
    "\n",
    "# confusion solved ;)\n",
    "# (size of W -> [outputs,inputs], but nn.Linear expects [inputs,outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "804bd9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T_destination',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__constants__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_call_impl',\n",
       " '_compiled_call_impl',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_load_from_state_dict',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_named_members',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_slow_forward',\n",
       " '_version',\n",
       " '_wrapped_call_impl',\n",
       " 'add_module',\n",
       " 'apply',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'compile',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'double',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'extra_repr',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'half',\n",
       " 'ipu',\n",
       " 'load_state_dict',\n",
       " 'modules',\n",
       " 'mtia',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'parameters',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_load_state_dict_pre_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_post_hook',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'reset_parameters',\n",
       " 'set_extra_state',\n",
       " 'set_submodule',\n",
       " 'share_memory',\n",
       " 'state_dict',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'train',\n",
       " 'type',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see all attributes of the class Linear\n",
    "dir(nn.Linear)\n",
    "\n",
    "# and the docstring for Linear.forward\n",
    "# ??nn.Linear.forward()\n",
    "# ??nn.Linear.__init__() # note the inputs vs. how weight is created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95366f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset (comes with colab!)\n",
    "data = np.loadtxt(open(\"../Datasets/mnist_train_small.csv\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# don't need labels!\n",
    "data = data[:, 1:]\n",
    "\n",
    "# normalize the data to a range of [0 1]\n",
    "dataNorm = data / np.max(data)\n",
    "\n",
    "# convert to tensor\n",
    "dataT = torch.tensor(dataNorm).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66677cf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
