{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b8b25c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Subset, TensorDataset\n",
    "\n",
    "from torchsummary import summary\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as T\n",
    "import copy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib_inline.backend_inline as backend_inline\n",
    "\n",
    "backend_inline.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "\n",
    "#### Pytorch device specific configuration ###\n",
    "\n",
    "# Pytorch Gpu Configuration for Cuda\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # Pytorch Gpu Configuration for directml(AMD GPU)\n",
    "# import torch_directml\n",
    "\n",
    "# device = torch_directml.device()\n",
    "\n",
    "# Set default device\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f58e031",
   "metadata": {},
   "outputs": [],
   "source": [
    "### MNIST data\n",
    "\n",
    "# import dataset\n",
    "data = np.loadtxt(open(\"../Datasets/mnist_train_small.csv\", \"rb\"), delimiter=\",\")\n",
    "\n",
    "# extract labels, normalize, reshape\n",
    "labelsT = torch.tensor(data[:, 0]).long()\n",
    "data = data[:, 1:]\n",
    "dataNorm = data / np.max(data)\n",
    "dataNormT = torch.tensor(dataNorm.reshape(dataNorm.shape[0], 1, 28, 28)).float()\n",
    "\n",
    "# split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(\n",
    "    dataNormT, labelsT, test_size=0.1\n",
    ")\n",
    "\n",
    "# convert into PyTorch Datasets\n",
    "train_data = TensorDataset(train_data, train_labels)\n",
    "test_data = TensorDataset(test_data, test_labels)\n",
    "\n",
    "# translate into dataloader objects\n",
    "batchsize = 32\n",
    "numbers_train_loader = DataLoader(\n",
    "    train_data, batch_size=batchsize, shuffle=True, drop_last=True, generator=torch.Generator(device=device)\n",
    ")\n",
    "numbers_test_loader = DataLoader(test_data, batch_size=test_data.tensors[0].shape[0], generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87b789b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### FMNIST data\n",
    "\n",
    "# transformations\n",
    "transform = T.Compose([T.ToTensor(), T.Normalize(0.5, 0.5)])\n",
    "\n",
    "# import the data and simultaneously apply the transform\n",
    "trainset = tv.datasets.FashionMNIST(\n",
    "    root=\"../Datasets/\", train=True, download=True, transform=transform\n",
    ")\n",
    "testset = tv.datasets.FashionMNIST(\n",
    "    root=\"../Datasets/\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# transform to dataloaders\n",
    "batchsize = 32\n",
    "fashion_train_loader = DataLoader(\n",
    "    trainset, batch_size=batchsize, shuffle=True, drop_last=True, generator=torch.Generator(device=device)\n",
    ")\n",
    "fashion_test_loader = DataLoader(testset, batch_size=len(testset), generator=torch.Generator(device=device))  ### FMNIST data\n",
    "\n",
    "# transformations\n",
    "transform = T.Compose([T.ToTensor(), T.Normalize(0.5, 0.5)])\n",
    "\n",
    "# import the data and simultaneously apply the transform\n",
    "trainset = tv.datasets.FashionMNIST(\n",
    "    root=\"../Datasets/\", train=True, download=True, transform=transform\n",
    ")\n",
    "testset = tv.datasets.FashionMNIST(\n",
    "    root=\"../Datasets/\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# transform to dataloaders\n",
    "batchsize = 32\n",
    "fashion_train_loader = DataLoader(\n",
    "    trainset, batch_size=batchsize, shuffle=True, drop_last=True, generator=torch.Generator(device=device)\n",
    ")\n",
    "fashion_test_loader = DataLoader(testset, batch_size=len(testset), generator=torch.Generator(device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97c37160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a class for the model\n",
    "def createTheMNISTNet(printtoggle=False):\n",
    "\n",
    "    class mnistNet(nn.Module):\n",
    "        def __init__(self, printtoggle):\n",
    "            super().__init__()\n",
    "\n",
    "            ### convolution layers\n",
    "            self.conv1 = nn.Conv2d(1, 10, kernel_size=5, stride=1, padding=1)\n",
    "            # size: np.floor( (28+2*1-5)/1 )+1 = 26/2 = 13 (/2 b/c maxpool)\n",
    "\n",
    "            self.conv2 = nn.Conv2d(10, 20, kernel_size=5, stride=1, padding=1)\n",
    "            # size: np.floor( (13+2*1-5)/1 )+1 = 11/2 = 5 (/2 b/c maxpool)\n",
    "\n",
    "            # compute the number of units in FClayer (number of outputs of conv2)\n",
    "            expectSize = (\n",
    "                np.floor((5 + 2 * 0 - 1) / 1) + 1\n",
    "            )  # fc1 layer has no padding or kernel, so set to 0/1\n",
    "            expectSize = 20 * int(expectSize**2)\n",
    "\n",
    "            ### fully-connected layer\n",
    "            self.fc1 = nn.Linear(expectSize, 50)\n",
    "\n",
    "            ### output layer\n",
    "            self.out = nn.Linear(50, 10)\n",
    "\n",
    "            # toggle for printing out tensor sizes during forward prop\n",
    "            self.print = printtoggle\n",
    "\n",
    "        # forward pass\n",
    "        def forward(self, x):\n",
    "\n",
    "            print(f\"Input: {x.shape}\") if self.print else None\n",
    "\n",
    "            # convolution -> maxpool -> relu\n",
    "            x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "            print(f\"Layer conv1: {x.shape}\") if self.print else None\n",
    "\n",
    "            # and again: convolution -> maxpool -> relu\n",
    "            x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "            print(f\"Layer conv2: {x.shape}\") if self.print else None\n",
    "\n",
    "            # reshape for linear layer\n",
    "            nUnits = x.shape.numel() / x.shape[0]\n",
    "            x = x.view(-1, int(nUnits))\n",
    "            if self.print:\n",
    "                print(f\"Vectorize: {x.shape}\")\n",
    "\n",
    "            # linear layers\n",
    "            x = F.relu(self.fc1(x))\n",
    "            if self.print:\n",
    "                print(f\"Layer fc1: {x.shape}\")\n",
    "            x = self.out(x)\n",
    "            if self.print:\n",
    "                print(f\"Layer out: {x.shape}\")\n",
    "\n",
    "            return x\n",
    "\n",
    "    # create the model instance\n",
    "    net = mnistNet(printtoggle)\n",
    "\n",
    "    # loss function\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer (NOTE: Using SGD here to slow down learning!)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=0.005)\n",
    "\n",
    "    return net, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1faa2349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that trains the model\n",
    "\n",
    "\n",
    "# input the network and the number of epochs to train\n",
    "def function2trainTheModel(net, train_loader, test_loader, numepochs=10):\n",
    "\n",
    "    # initialize losses\n",
    "    losses = torch.zeros(numepochs)\n",
    "    trainAcc = []\n",
    "    testAcc = []\n",
    "\n",
    "    # loop over epochs\n",
    "    for epochi in range(numepochs):\n",
    "\n",
    "        # loop over training data batches\n",
    "        net.train()\n",
    "        batchAcc = []\n",
    "        batchLoss = []\n",
    "        for X, y in train_loader:\n",
    "\n",
    "            # forward pass and loss\n",
    "            yHat = net(X)\n",
    "            loss = lossfun(yHat, y)\n",
    "\n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # loss from this batch\n",
    "            batchLoss.append(loss.item())\n",
    "\n",
    "            # compute accuracy\n",
    "            matches = torch.argmax(yHat, axis=1) == y  # booleans (false/true)\n",
    "            matchesNumeric = matches.float()  # convert to numbers (0/1)\n",
    "            accuracyPct = 100 * torch.mean(matchesNumeric)  # average and x100\n",
    "            batchAcc.append(accuracyPct)  # add to list of accuracies\n",
    "        # end of batch loop...\n",
    "\n",
    "        # now that we've trained through the batches, get their average training accuracy\n",
    "        trainAcc.append(np.mean(batchAcc))\n",
    "\n",
    "        # and get average losses across the batches\n",
    "        losses[epochi] = np.mean(batchLoss)\n",
    "\n",
    "        # test accuracy\n",
    "        net.eval()\n",
    "        X, y = next(iter(test_loader))  # extract X,y from test dataloader\n",
    "        with torch.no_grad():  # deactivates autograd\n",
    "            yHat = net(X)\n",
    "\n",
    "        # compute test accuracy\n",
    "        testAcc.append(100 * torch.mean((torch.argmax(yHat, axis=1) == y).float()))\n",
    "\n",
    "    # end epochs\n",
    "\n",
    "    # function output\n",
    "    return trainAcc, testAcc, losses, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f29ee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
