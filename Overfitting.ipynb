{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Pytorch Gpu Configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.set_default_device(device)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Matplotlib svg plots for better pictures\n",
    "import matplotlib_inline.backend_inline\n",
    "\n",
    "matplotlib_inline.backend_inline.set_matplotlib_formats(\"svg\")\n",
    "\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from torchsummary import summary\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataset\n",
    "iris = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
    ")\n",
    "\n",
    "# Convert dataset from pandas datafram to tensor\n",
    "data = torch.tensor(iris[iris.columns[0:4]].values).float()\n",
    "\n",
    "# transform species to number\n",
    "labels = torch.zeros(len(data), dtype=torch.long)\n",
    "labels[iris.species == \"setosa\"] = (\n",
    "    0  # We don't need this line as torch.zeros initialize the tensor with zeros\n",
    ")\n",
    "labels[iris.species == \"versicolor\"] = 1\n",
    "labels[iris.species == \"virginica\"] = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test split manual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True  True  True  True  True  True  True  True  True False\n",
      "  True  True  True False  True False False False False False  True  True\n",
      " False  True  True False  True  True False  True  True  True False  True\n",
      " False  True  True  True  True  True False  True False  True  True  True\n",
      "  True  True  True  True False  True  True  True  True  True  True False\n",
      " False  True  True  True  True  True  True  True  True  True False  True\n",
      "  True False  True  True  True False  True  True False  True False False\n",
      "  True  True False  True  True  True False  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True False  True  True False\n",
      "  True  True  True  True  True  True  True False  True  True  True  True\n",
      "  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Seperate data into train and test sets\n",
    "\n",
    "# Training Examples\n",
    "propTrain = 0.8  # in proportion not percent\n",
    "nTraining = int(len(labels) * propTrain)\n",
    "\n",
    "# initialize a boolean vector to select data and labels\n",
    "trainTestBool = np.zeros(len(labels), dtype=bool)\n",
    "\n",
    "# trainTestBool[range(nTraining)] = True # Not the right way to do the split because it will not randomise data\n",
    "\n",
    "# This is the better way\n",
    "items2use4train = np.random.choice(range(len(labels)), nTraining, replace=False)\n",
    "trainTestBool[items2use4train] = True\n",
    "\n",
    "\n",
    "print(trainTestBool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of full data: 1.0\n",
      " \n",
      "Average of training data: 1.008333444595337\n",
      " \n",
      "Average of test data: 0.9666666984558105\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# Let's check wether train and test are balanced or not?\n",
    "print(f\"Average of full data: {torch.mean(labels.float())}\")\n",
    "print(\" \")\n",
    "print(f\"Average of training data: {torch.mean(labels[trainTestBool].float())}\")\n",
    "print(\" \")\n",
    "print(f\"Average of test data: {torch.mean(labels[~trainTestBool].float())}\")\n",
    "print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "NNModelIris = nn.Sequential(\n",
    "    nn.Linear(4, 128), nn.ReLU(), nn.Linear(128, 64), nn.ReLU(), nn.Linear(64, 3)\n",
    ")\n",
    "# Loss Function\n",
    "lossFun = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(NNModelIris.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete data shape: torch.Size([150, 4])\n",
      "Training data shape: torch.Size([120, 4])\n",
      "Testing data shape: torch.Size([30, 4])\n"
     ]
    }
   ],
   "source": [
    "# Complete Dataset Shape\n",
    "print(f\"Complete data shape: {data.shape}\")\n",
    "# Training Dataset Shape\n",
    "print(f\"Training data shape: {data[trainTestBool, :].shape}\")\n",
    "# Testing Dataset Shape\n",
    "print(f\"Testing data shape: {data[~trainTestBool, :].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "nEpochs = 1000\n",
    "\n",
    "# initialize losses\n",
    "losses = torch.zeros(nEpochs)\n",
    "ongoingAcc = []\n",
    "\n",
    "# Loop over epochs\n",
    "for epoch in range(nEpochs):\n",
    "\n",
    "    # Forward pass\n",
    "    yHat = NNModelIris(data[trainTestBool, :])\n",
    "\n",
    "    # Compute accuracy\n",
    "    ongoingAcc.append(\n",
    "        100\n",
    "        * torch.mean(\n",
    "            (torch.argmax(yHat, axis=1) == labels[trainTestBool]).cpu().float()\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Compute Loss\n",
    "    loss = lossFun(yHat, labels[trainTestBool])\n",
    "    losses[epoch] = loss\n",
    "\n",
    "    # Backprop\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Train accuracy: 98.33333587646484\n",
      "Final test accuracy: 96.66666412353516\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "\n",
    "# Compute train accuracy\n",
    "predictions_train = NNModelIris(data[trainTestBool, :])\n",
    "trainAccuracy = 100 * torch.mean(\n",
    "    (torch.argmax(predictions_train, axis=1) == labels[trainTestBool]).cpu().float()\n",
    ")\n",
    "\n",
    "# Compute Test accuracy\n",
    "predictions_test = NNModelIris(data[~trainTestBool, :])\n",
    "testAccuracy = 100 * torch.mean(\n",
    "    (torch.argmax(predictions_test, axis=1) == labels[~trainTestBool]).cpu().float()\n",
    ")\n",
    "\n",
    "print(f\"Final Train accuracy: {trainAccuracy}\")\n",
    "print(f\"Final test accuracy: {testAccuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split Using sklearn train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 11,  12,  13,  14],\n",
       "        [ 21,  22,  23,  24],\n",
       "        [ 31,  32,  33,  34],\n",
       "        [ 41,  42,  43,  44],\n",
       "        [ 51,  52,  53,  54],\n",
       "        [ 61,  62,  63,  64],\n",
       "        [ 71,  72,  73,  74],\n",
       "        [ 81,  82,  83,  84],\n",
       "        [ 91,  92,  93,  94],\n",
       "        [101, 102, 103, 104]]),\n",
       " array([False, False, False, False, False,  True,  True,  True,  True,\n",
       "         True]))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fakeData = (\n",
    "    np.tile(np.array([1, 2, 3, 4]), (10, 1)) + np.tile(10 * np.arange(1, 11), (4, 1)).T\n",
    ")\n",
    "fakeLabels = np.arange(10) > 4\n",
    "fakeData, fakeLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size: (8, 4)\n",
      "Test data size: (2, 4)\n",
      " \n",
      "Training data: \n",
      "[[ 21  22  23  24]\n",
      " [ 71  72  73  74]\n",
      " [ 41  42  43  44]\n",
      " [ 91  92  93  94]\n",
      " [ 51  52  53  54]\n",
      " [101 102 103 104]\n",
      " [ 81  82  83  84]\n",
      " [ 11  12  13  14]]\n",
      " \n",
      "Test data: \n",
      "[[61 62 63 64]\n",
      " [31 32 33 34]]\n"
     ]
    }
   ],
   "source": [
    "# Use scikitlearn to split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(fakeData, fakeLabels, test_size=0.2, train_size=0.8)\n",
    "\n",
    "# print out the sizes\n",
    "print(\"Training data size: \" + str(train_data.shape))\n",
    "print(\"Test data size: \" + str(test_data.shape))\n",
    "print(\" \")\n",
    "\n",
    "# print out the train/test data\n",
    "print(\"Training data: \")\n",
    "print(train_data)\n",
    "print(\" \")\n",
    "\n",
    "print(\"Test data: \")\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that creates the ANN model\n",
    "\n",
    "\n",
    "def createANewModel():\n",
    "\n",
    "    # model architecture\n",
    "    ANNiris = nn.Sequential(\n",
    "        nn.Linear(4, 64),  # input layer\n",
    "        nn.ReLU(),  # activation unit\n",
    "        nn.Linear(64, 64),  # hidden layer\n",
    "        nn.ReLU(),  # activation unit\n",
    "        nn.Linear(64, 3),  # output units\n",
    "    )\n",
    "\n",
    "    # loss function\n",
    "    lossfun = nn.CrossEntropyLoss()\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = torch.optim.SGD(ANNiris.parameters(), lr=0.01)\n",
    "\n",
    "    return ANNiris, lossfun, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
